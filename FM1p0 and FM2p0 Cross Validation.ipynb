{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import importlib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix, roc_auc_score,average_precision_score,f1_score,ConfusionMatrixDisplay\n",
    "from xgboost import XGBClassifier\n",
    "import shap\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from statistics import mean\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import re\n",
    "import pickle\n",
    "from matplotlib import pyplot\n",
    "import time\n",
    "import scispacy\n",
    "import spacy\n",
    "import nltk\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to generate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "def feature_gen(dataframe,include_bigrams='FALSE'):\n",
    "    \n",
    "    meas_method_column_vals = []\n",
    "    entity_nlp = spacy.load('en_core_web_sm')\n",
    "    chemical_disease_nlp = spacy.load('en_core_web_md')\n",
    "    chem_ent_ratios, seen_chem, chem_count = [], [], []\n",
    "    human_bigram = []    \n",
    "    for index, row in dataframe.iterrows():\n",
    "        abstract = row['abstract']\n",
    "    #   ------------ Chemical Names ----------------\n",
    "        entity_doc = entity_nlp(abstract)\n",
    "        chemical_disease_doc = chemical_disease_nlp(abstract)\n",
    "        chemical_ents = [ent.text for ent in chemical_disease_doc.ents if ent.label_ == 'CHEMICAL']\n",
    "        if len(entity_doc.ents) == 0:\n",
    "            chem_ent_ratios.append(0)\n",
    "        else:\n",
    "            chem_ent_ratios.append(len(chemical_ents) / len(entity_doc.ents))\n",
    "        seen_chem.append(list(set(chemical_ents)))\n",
    "        chem_count.append(len(chemical_ents))\n",
    "    #   ------------ Bigram Score --------------\n",
    "        if include_bigrams == 'TRUE':\n",
    "            tokens = nltk.word_tokenize(abstract)\n",
    "            bigrams = nltk.bigrams(tokens)\n",
    "            stopset = set(stopwords.words('english') + list(string.punctuation))\n",
    "            milk_bigrams = [(w1, w2) for w1, w2 in bigrams if \n",
    "                            (w1.lower() == 'milk' or w2.lower() == 'milk')\n",
    "                             and (w1.lower() not in stopset and w2.lower() not in stopset)]\n",
    "            human_bigrams = [(w1, w2) for w1, w2 in milk_bigrams if \n",
    "                             (w1.lower() == 'human' or w2.lower() == 'human')\n",
    "                             and (w1.lower() not in stopset and w2.lower() not in stopset)]\n",
    "            human_bigram.append(len(human_bigrams) / len(milk_bigrams) if len(milk_bigrams) != 0 else 0)\n",
    "        else:\n",
    "            human_bigram.append(0.0)\n",
    "\n",
    "    dataframe['chem_ent_ratio'] = chem_ent_ratios\n",
    "    dataframe['chemicals'] = seen_chem\n",
    "    dataframe['bigram_score'] = human_bigram\n",
    "    dataframe['chem_term_count'] = chem_count\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi']= 150\n",
    "\n",
    "def clean_plot(leg=True, grid=None, font=None):\n",
    "    ax = plt.gca()\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    axis_color = 'lightgrey'\n",
    "    ax.spines['bottom'].set_color(axis_color)\n",
    "    ax.spines['left'].set_color(axis_color)\n",
    "    ax.tick_params(axis='both', color=axis_color)\n",
    "    \n",
    "    if leg:\n",
    "        ax.legend(frameon = False, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "        \n",
    "    if grid is not None:\n",
    "        plt.grid(color='lightgrey', axis = grid, linestyle='-', linewidth=.5)\n",
    "        \n",
    "    if font is not None:\n",
    "        for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n",
    "            ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "            \n",
    "            item.set_fontfamily(font['family'])\n",
    "            item.set_color(font['color'])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\parth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from src.filter import Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading datasets and generating features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "## Garlic and Cocoa\n",
    "\n",
    "gtrain = pd.read_csv(\"data/garlic_scoring.csv\", encoding='latin1')[['PMID', 'abstract', 'paper', 'mesh_terms', 'qual_terms', 'is_useful']]\n",
    "gtrain['food'] = 'garlic'\n",
    "ctrain = pd.read_csv(\"data/cocoa_scoring.csv\", encoding='latin1')[['PMID', 'abstract', 'paper', 'mesh_terms', 'qual_terms', 'is_useful']]\n",
    "ctrain['food'] = 'cocoa'\n",
    "gtrain['is_useful'] = gtrain['is_useful'].replace(2, 1, regex=True)\n",
    "ctrain['is_useful'] = ctrain['is_useful'].replace(2, 1, regex=True)\n",
    "gtrain = gtrain[gtrain['is_useful'].notnull()]\n",
    "ctrain = ctrain[ctrain['is_useful'].notnull()]\n",
    "\n",
    "## Basil\n",
    "\n",
    "btrain = pd.read_excel(\"data/basil_scoring.xls\")[['PMID', 'abstract', 'paper', 'mesh_terms', 'qual_terms', 'is_useful']]\n",
    "btrain['food'] = 'apple'\n",
    "\n",
    "for i in range(len(btrain)):\n",
    "    if btrain['is_useful'].loc[i] == 'x':\n",
    "        btrain['is_useful'].loc[i] = 0\n",
    "        \n",
    "btrain['is_useful'] = btrain['is_useful'].replace(2, 1, regex=True)\n",
    "btrain = btrain[btrain['is_useful'].notnull()]\n",
    "\n",
    "## Apple\n",
    "\n",
    "atrain = pd.read_excel(\"data/apple_scoring.xls\")[['PMID', 'abstract', 'paper', 'mesh_terms', 'qual_terms', 'is_useful']]\n",
    "atrain['food'] = 'apple'\n",
    "\n",
    "for i in range(len(atrain)):\n",
    "    if atrain['is_useful'].loc[i] == 'x':\n",
    "        atrain['is_useful'].loc[i] = 0\n",
    "\n",
    "atrain['is_useful'] = atrain['is_useful'].replace(2, 1, regex=True)\n",
    "atrain = atrain[atrain['is_useful'].notnull()]\n",
    "atrain = atrain[atrain['abstract'].notnull()]\n",
    "atrain = atrain[atrain['PMID'].notnull()]\n",
    "\n",
    "## Human Milk database\n",
    "\n",
    "mtrain_new = pd.read_csv(\"mBase_15Aug_abstract[chemical_gen].csv\")\n",
    "mtrain_new['food'] = 'milk'\n",
    "mtrain_new = mtrain_new[mtrain_new['abstract'].notnull()]\n",
    "mtrain_new = mtrain_new[mtrain_new['PMID'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the databases for garlic, cocoa, basil, apple, milk:  299 324 93 1653 229\n"
     ]
    }
   ],
   "source": [
    "print('Length of the databases for garlic, cocoa, basil, apple, milk: ', len(gtrain), len(ctrain), len(btrain), len(atrain), len(mtrain_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Useful and non-useful:  77 222\n"
     ]
    }
   ],
   "source": [
    "print('Useful and non-useful: ',len(gtrain[gtrain['is_useful'] == 1.0]),len(gtrain[gtrain['is_useful'] == 0.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Useful and non-useful:  93 231\n"
     ]
    }
   ],
   "source": [
    "print('Useful and non-useful: ',len(ctrain[ctrain['is_useful'] == 1.0]),len(ctrain[ctrain['is_useful'] == 0.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Useful and non-useful:  462 1191\n"
     ]
    }
   ],
   "source": [
    "print('Useful and non-useful: ',len(atrain[atrain['is_useful'] == 1.0]),len(atrain[atrain['is_useful'] == 0.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Useful and non-useful:  57 36\n"
     ]
    }
   ],
   "source": [
    "print('Useful and non-useful: ',len(btrain[btrain['is_useful'] == 1.0]),len(btrain[btrain['is_useful'] == 0.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_all_features(ftrain,include_bigrams='FALSE'):\n",
    "    fmodel_data = Filter()\n",
    "\n",
    "    fmodel_data.build_features(input_data = ftrain,is_traindata = True)\n",
    "\n",
    "    ftrain = feature_gen(ftrain,include_bigrams)\n",
    "\n",
    "    fmodel_data.data['chem_ent_ratio'] = ftrain['chem_ent_ratio'].values\n",
    "    fmodel_data.data['chem_term_count'] = ftrain['chem_term_count'].values\n",
    "    fmodel_data.data['bigram_score'] = ftrain['bigram_score'].values\n",
    "    \n",
    "    return fmodel_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Starting feature generation----\n",
      "Creating features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "299it [02:20,  2.13it/s]\n",
      "[W095] Model 'en_core_web_md' (3.5.0) was trained with spaCy v3.5.0 and may not be 100% compatible with the current version (3.6.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----DONE----\n",
      "Creating features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "324it [02:13,  2.43it/s]\n",
      "[W095] Model 'en_core_web_md' (3.5.0) was trained with spaCy v3.5.0 and may not be 100% compatible with the current version (3.6.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----DONE----\n",
      "Creating features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "93it [00:38,  2.43it/s]\n",
      "[W095] Model 'en_core_web_md' (3.5.0) was trained with spaCy v3.5.0 and may not be 100% compatible with the current version (3.6.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----DONE----\n"
     ]
    }
   ],
   "source": [
    "print('----Starting feature generation----')\n",
    "gdata = build_all_features(gtrain,include_bigrams='FALSE')\n",
    "print('----DONE----')\n",
    "cdata = build_all_features(ctrain,include_bigrams='FALSE')\n",
    "print('----DONE----')\n",
    "bdata = build_all_features(btrain,include_bigrams='FALSE')\n",
    "print('----DONE----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Starting feature generation----\n",
      "Creating features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1653it [14:24,  1.91it/s]\n",
      "[W095] Model 'en_core_web_md' (3.5.0) was trained with spaCy v3.5.0 and may not be 100% compatible with the current version (3.6.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----DONE----\n",
      "Creating features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "229it [01:16,  3.00it/s]\n",
      "[W095] Model 'en_core_web_md' (3.5.0) was trained with spaCy v3.5.0 and may not be 100% compatible with the current version (3.6.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----DONE----\n"
     ]
    }
   ],
   "source": [
    "print('----Starting feature generation----')\n",
    "adata = build_all_features(atrain,include_bigrams='FALSE')\n",
    "print('----DONE----')\n",
    "mdata = build_all_features(mtrain_new,include_bigrams='TRUE')\n",
    "print('----DONE----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdata_features_class = gdata.data.copy()\n",
    "cdata_features_class = cdata.data.copy()\n",
    "bdata_features_class = bdata.data.copy()\n",
    "adata_features_class = adata.data.copy()\n",
    "mdata_features_class = mdata.data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gdata_features_class.to_csv('data_with_feature/gdata_features_class.csv')\n",
    "cdata_features_class.to_csv('data_with_feature/cdata_features_class.csv')\n",
    "bdata_features_class.to_csv('data_with_feature/bdata_features_class.csv')\n",
    "adata_features_class.to_csv('data_with_feature/adata_features_class.csv')\n",
    "mdata_features_class.to_csv('data_with_feature/mdata_features_class.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdata_features_class = pd.read_csv('data_with_feature/gdata_features_class.csv')\n",
    "cdata_features_class = pd.read_csv('data_with_feature/cdata_features_class.csv')\n",
    "bdata_features_class = pd.read_csv('data_with_feature/bdata_features_class.csv')\n",
    "adata_features_class = pd.read_csv('data_with_feature/adata_features_class.csv')\n",
    "mdata_features_class = pd.read_csv('data_with_feature/mdata_features_class.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2vec trained on FoodBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmine = pd.read_csv('FoodBase_Abstracts_embeddings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_list = []\n",
    "\n",
    "for index, row in fmine.iterrows():\n",
    "    local_list = []\n",
    "    for x in row['vectors'].replace('[','').replace(']','').replace('\\n',' ').replace('  ',' ').replace('   ',' ').split(' '):\n",
    "        if x != '':\n",
    "            local_list.append(float(x))\n",
    "    embedding_list.append(local_list)\n",
    "    \n",
    "fmine['embeddings'] = embedding_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "abstract_embedding_dict = dict()\n",
    "\n",
    "for index, row in fmine.iterrows():\n",
    "    abstract_embedding_dict[row['abstract']] = row['embeddings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of Doc2Vec:  64\n"
     ]
    }
   ],
   "source": [
    "print('Dimension of Doc2Vec: ', len(embedding_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fmine_expanded = pd.concat([fmine, fmine['embeddings'].apply(pd.Series)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gdata_train_doc2vec = pd.merge(gtrain, fmine_expanded[fmine_expanded['food'] == 'garlic'], on=['abstract'])\n",
    "gdata_features_class_doc2vec = pd.merge(gdata_train_doc2vec, gdata_features_class, on=['PMID'])\n",
    "gdata_features_class_doc2vec = gdata_features_class_doc2vec.drop(columns=['PMID','abstract','paper','mesh_terms','qual_terms','is_useful_x','food_x','is_useful_y','food_y','vectors','embeddings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdata_train_doc2vec = pd.merge(ctrain, fmine_expanded[fmine_expanded['food'] == 'cocoa'], on=['abstract'])\n",
    "cdata_features_class_doc2vec = pd.merge(cdata_train_doc2vec, cdata_features_class, on=['PMID'])\n",
    "cdata_features_class_doc2vec = cdata_features_class_doc2vec.drop(columns=['PMID','abstract','paper','mesh_terms','qual_terms','is_useful_x','food_x','is_useful_y','food_y','vectors','embeddings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bdata_train_doc2vec = pd.merge(btrain, fmine_expanded[fmine_expanded['food'] == 'basil'], on=['abstract'])\n",
    "bdata_features_class_doc2vec = pd.merge(bdata_train_doc2vec, bdata_features_class, on=['PMID'])\n",
    "bdata_features_class_doc2vec = bdata_features_class_doc2vec.drop(columns=['PMID','abstract','paper','mesh_terms','qual_terms','is_useful_x','food_x','is_useful_y','food_y','vectors','embeddings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adata_train_doc2vec = pd.merge(atrain, fmine_expanded[fmine_expanded['food'] == 'apple'], on=['abstract'])\n",
    "adata_features_class_doc2vec = pd.merge(adata_train_doc2vec, adata_features_class, on=['PMID'])\n",
    "adata_features_class_doc2vec = adata_features_class_doc2vec.drop(columns=['PMID','abstract','paper','mesh_terms','qual_terms','is_useful_x','food_x','is_useful_y','food_y','vectors','embeddings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdata_train_doc2vec = pd.merge(mtrain_new, fmine_expanded[fmine_expanded['food'] == 'human milk'], on=['abstract'])\n",
    "mdata_features_class_doc2vec = pd.merge(mdata_train_doc2vec, mdata_features_class, on=['PMID'])\n",
    "mdata_features_class_doc2vec = mdata_features_class_doc2vec.drop(columns=['PMID','abstract','paper','mesh_terms','qual_terms','is_useful_x','food_x','is_useful_y','food_y','vectors','embeddings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdata_features_class_doc2vec = mdata_features_class_doc2vec.drop(columns=['journal','mesh_UIds','qual_UIds','webpage','year','source','measmethod','chem_ent_ratio_x','chemicals','bigram_score_x','chem_term_count_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdata_features_class_doc2vec = mdata_features_class_doc2vec.rename(columns={'chem_ent_ratio_y':'chem_ent_ratio','chem_term_count_y':'chem_term_count','bigram_score_y':'bigram_score'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(total_data):\n",
    "    total_data_features = total_data.drop(columns=['class'])\n",
    "    for col_feature in list(total_data_features.columns): \n",
    "        col_list = total_data_features[col_feature].tolist()\n",
    "        if col_list != [0.0] * len(col_list):\n",
    "            col_list_normalized = [(x-np.mean(col_list))/np.std(col_list) for x in col_list]\n",
    "        else:\n",
    "            col_list_normalized = col_list\n",
    "        total_data_features[col_feature] = col_list_normalized\n",
    "    # total_data_features_normalized = (total_data_features-total_data_features.mean())/total_data_features.std()\n",
    "    # total_data_features_normalized = (total_data_features-total_data_features.min())/(total_data_features.max()-total_data_features.min())\n",
    "    total_data_features['class'] = total_data['class'].tolist()\n",
    "    \n",
    "    return total_data_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gdata_features_class_normalized = normalize_features(gdata_features_class)\n",
    "cdata_features_class_normalized = normalize_features(cdata_features_class)\n",
    "bdata_features_class_normalized = normalize_features(bdata_features_class)\n",
    "adata_features_class_normalized = normalize_features(adata_features_class)\n",
    "mdata_features_class_normalized = normalize_features(mdata_features_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm1p0_columns = ['chromatography', 'food_term_count', 'gen_term_count', 'sci_term_count', 'spectrometry', 'spectrophotometry']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performances on seen food "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def xgboost_model(x,y,kfold,n_splits=10,fm1p0_columns=fm1p0_columns):\n",
    "\n",
    "    cross_val_model_fm1 = RandomForestClassifier(max_depth=80,random_state=0)\n",
    "    cross_val_model_fm2 = RandomForestClassifier(max_depth=80,random_state=0)\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits)\n",
    "    \n",
    "    auc_fm1 = []\n",
    "    aup_fm1 = []\n",
    "    f1_score_list_fm1 = []\n",
    "    \n",
    "    auc_fm2 = []\n",
    "    aup_fm2 = []\n",
    "    f1_score_list_fm2 = []\n",
    "    \n",
    "    for i,(train,test) in enumerate(kfold.split(x,y)):\n",
    "        \n",
    "        x_old = x[fm1p0_columns]\n",
    "        \n",
    "        cross_val_model_fm2.fit(x.loc[train],y.loc[train])\n",
    "        cross_val_model_fm1.fit(x_old.loc[train],y.loc[train])\n",
    "        \n",
    "        #viz_fm1 = plot_roc_curve(cross_val_model_fm1, x_old.loc[test], y.loc[test],\n",
    "        #                 name='ROC fold {}'.format(i),\n",
    "        #                 alpha=0.3, lw=1)\n",
    "        #viz_fm2 = plot_roc_curve(cross_val_model_fm2, x.loc[test], y.loc[test],\n",
    "        #                 name='ROC fold {}'.format(i),\n",
    "        #                 alpha=0.3, lw=1)\n",
    "        \n",
    "        y_predicted_fm1 = cross_val_model_fm1.predict(x_old.loc[test])\n",
    "        y_predicted_fm2 = cross_val_model_fm2.predict(x.loc[test])\n",
    "        \n",
    "        auc_fm1.append(roc_auc_score(np.array(y.loc[test].tolist()),y_predicted_fm1))\n",
    "        aup_fm1.append(average_precision_score(np.array(y.loc[test].tolist()),y_predicted_fm1))\n",
    "        f1_score_list_fm1.append(f1_score(np.array(y.loc[test].tolist()),y_predicted_fm1))\n",
    "        \n",
    "        auc_fm2.append(roc_auc_score(np.array(y.loc[test].tolist()),y_predicted_fm2))\n",
    "        aup_fm2.append(average_precision_score(np.array(y.loc[test].tolist()),y_predicted_fm2))\n",
    "        f1_score_list_fm2.append(f1_score(np.array(y.loc[test].tolist()),y_predicted_fm2))\n",
    "        # plot_confusion_matrix(cross_val_model,x.loc[test],y.loc[test])\n",
    "        \n",
    "    print('------------------------------------------------------------------------------------------------------')\n",
    "    print('FoodMine1.0')\n",
    "    print('Average and SD of AUROC: ', mean(auc_fm1), np.std(auc_fm1))\n",
    "    print('Average and SD of AUPRC:', mean(aup_fm1), np.std(aup_fm1))\n",
    "    print('Average and SD of f1-Score:', mean(f1_score_list_fm1), np.std(f1_score_list_fm1))\n",
    "    print('All AUROC values: ', auc_fm1)\n",
    "    print('All AUPRC values: ', aup_fm1)\n",
    "    print('All f1-Score values: ', f1_score_list_fm1)\n",
    "    print('------------------------------------------------------------------------------------------------------')\n",
    "    print('FoodMine2.0')\n",
    "    print('Average and SD of AUROC: ', mean(auc_fm2), np.std(auc_fm2))\n",
    "    print('Average and SD of AUPRC:', mean(aup_fm2), np.std(aup_fm2))\n",
    "    print('Average and SD of f1-Score:', mean(f1_score_list_fm2), np.std(f1_score_list_fm2))\n",
    "    print('All AUROC values: ', auc_fm2)\n",
    "    print('All AUPRC values: ', aup_fm2)\n",
    "    print('All f1-Score values: ', f1_score_list_fm2)\n",
    "    print('------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "    return mean(auc_fm2), mean(aup_fm2), mean(f1_score_list_fm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_cross_validation_seen_food(fdata_features_class_normalized):\n",
    "\n",
    "    repeat = 1\n",
    "\n",
    "    for _ in tqdm(range(repeat)):\n",
    "        oversample = SMOTE()\n",
    "        y = fdata_features_class_normalized.copy()['class']\n",
    "        X = fdata_features_class_normalized.copy().drop('class', axis = 1)\n",
    "        X = fdata_features_class_normalized.copy().drop('chemicals', axis = 1)\n",
    "        X.columns = X.columns.astype(str)\n",
    "        X_smote, y_smote = oversample.fit_resample(X, y)\n",
    "        kfold = StratifiedKFold(n_splits=10)\n",
    "        auc_fm2, aup_fm2, f1_fm2 = xgboost_model(X_smote, y_smote,kfold,n_splits=10)\n",
    "        \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------\n",
      "FoodMine1.0\n",
      "Average and SD of AUROC:  0.7764822134387351 0.13656240883157408\n",
      "Average and SD of AUPRC: 0.7356675611668636 0.11780240217446954\n",
      "Average and SD of f1-Score: 0.7198902336956919 0.21598530465828072\n",
      "All AUROC values:  [0.6521739130434783, 0.516798418972332, 0.6146245059288538, 0.708498023715415, 0.8636363636363635, 0.8863636363636364, 0.9090909090909092, 0.9090909090909092, 0.9090909090909091, 0.7954545454545454]\n",
      "All AUPRC values:  [0.659903381642512, 0.5200702678963548, 0.5893217893217892, 0.6518716577540107, 0.7937062937062938, 0.8148148148148148, 0.8579545454545454, 0.8579545454545454, 0.8719008264462809, 0.7391774891774892]\n",
      "All f1-Score values:  [0.4666666666666667, 0.3529411764705882, 0.41379310344827586, 0.6666666666666667, 0.875, 0.8979591836734693, 0.9130434782608695, 0.9130434782608695, 0.9090909090909091, 0.7906976744186046]\n",
      "------------------------------------------------------------------------------------------------------\n",
      "FoodMine2.0\n",
      "Average and SD of AUROC:  1.0 0.0\n",
      "Average and SD of AUPRC: 1.0 0.0\n",
      "Average and SD of f1-Score: 1.0 0.0\n",
      "All AUROC values:  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "All AUPRC values:  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "All f1-Score values:  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Garlic\n",
    "get_cross_validation_seen_food(gdata_features_class_doc2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------\n",
      "FoodMine1.0\n",
      "Average and SD of AUROC:  0.7192028985507246 0.1852934116292177\n",
      "Average and SD of AUPRC: 0.6901133856464569 0.15447645115041672\n",
      "Average and SD of f1-Score: 0.6344240302181479 0.2943318615643008\n",
      "All AUROC values:  [0.5235507246376812, 0.5815217391304348, 0.4782608695652174, 0.41304347826086957, 0.891304347826087, 0.8260869565217391, 0.9130434782608695, 0.8478260869565217, 0.8695652173913044, 0.8478260869565217]\n",
      "All AUPRC values:  [0.5037927844588344, 0.5704787234042553, 0.4901185770750988, 0.47101449275362317, 0.8557312252964426, 0.7536231884057971, 0.8933747412008282, 0.7809364548494984, 0.8011272141706924, 0.7809364548494984]\n",
      "All f1-Score values:  [0.21428571428571427, 0.375, 0.29411764705882354, 0.22857142857142854, 0.888888888888889, 0.84, 0.909090909090909, 0.8571428571428572, 0.8800000000000001, 0.8571428571428572]\n",
      "------------------------------------------------------------------------------------------------------\n",
      "FoodMine2.0\n",
      "Average and SD of AUROC:  1.0 0.0\n",
      "Average and SD of AUPRC: 1.0 0.0\n",
      "Average and SD of f1-Score: 1.0 0.0\n",
      "All AUROC values:  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "All AUPRC values:  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "All f1-Score values:  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Cocoa\n",
    "get_cross_validation_seen_food(cdata_features_class_doc2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------\n",
      "FoodMine1.0\n",
      "Average and SD of AUROC:  0.5833333333333334 0.15509853498842457\n",
      "Average and SD of AUPRC: 0.5783513708513709 0.11569540797589978\n",
      "Average and SD of f1-Score: 0.5425574425574425 0.16970215608483222\n",
      "All AUROC values:  [0.41666666666666663, 0.7500000000000002, 0.41666666666666663, 0.33333333333333337, 0.5499999999999999, 0.6500000000000001, 0.75, 0.8166666666666667, 0.5166666666666667, 0.6333333333333334]\n",
      "All AUPRC values:  [0.4666666666666667, 0.6785714285714286, 0.4642857142857143, 0.4444444444444445, 0.5727272727272728, 0.6477272727272727, 0.7727272727272727, 0.730909090909091, 0.4636363636363636, 0.5418181818181818]\n",
      "All f1-Score values:  [0.3636363636363636, 0.7692307692307692, 0.4615384615384615, 0.3333333333333333, 0.5454545454545454, 0.6, 0.6666666666666666, 0.8000000000000002, 0.28571428571428575, 0.6]\n",
      "------------------------------------------------------------------------------------------------------\n",
      "FoodMine2.0\n",
      "Average and SD of AUROC:  0.99 0.029999999999999992\n",
      "Average and SD of AUPRC: 0.9857142857142858 0.04285714285714287\n",
      "Average and SD of f1-Score: 0.9923076923076923 0.023076923076923096\n",
      "All AUROC values:  [1.0, 1.0, 1.0, 1.0, 1.0, 0.9, 1.0, 1.0, 1.0, 1.0]\n",
      "All AUPRC values:  [1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0]\n",
      "All f1-Score values:  [1.0, 1.0, 1.0, 1.0, 1.0, 0.923076923076923, 1.0, 1.0, 1.0, 1.0]\n",
      "------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Basil\n",
    "get_cross_validation_seen_food(bdata_features_class_doc2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:16<00:00, 16.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------\n",
      "FoodMine1.0\n",
      "Average and SD of AUROC:  0.5869257703081232 0.05668365058735479\n",
      "Average and SD of AUPRC: 0.552239400494523 0.03615589989295591\n",
      "Average and SD of f1-Score: 0.5974663616606625 0.09344150941431156\n",
      "All AUROC values:  [0.5436274509803922, 0.5189075630252101, 0.5168067226890757, 0.5126050420168067, 0.6302521008403361, 0.6260504201680672, 0.680672268907563, 0.634453781512605, 0.6134453781512605, 0.592436974789916]\n",
      "All AUPRC values:  [0.5219604947566032, 0.5119155903219939, 0.5087463556851312, 0.5065015479876162, 0.5784962991819245, 0.5773491214667685, 0.6167609901103299, 0.5813799203892083, 0.56686515665869, 0.5524185283869645]\n",
      "All f1-Score values:  [0.5067873303167422, 0.5106382978723404, 0.4700460829493087, 0.45794392523364486, 0.674074074074074, 0.6454183266932272, 0.7142857142857144, 0.6789667896678967, 0.6592592592592592, 0.6572438162544169]\n",
      "------------------------------------------------------------------------------------------------------\n",
      "FoodMine2.0\n",
      "Average and SD of AUROC:  1.0 0.0\n",
      "Average and SD of AUPRC: 1.0 0.0\n",
      "Average and SD of f1-Score: 1.0 0.0\n",
      "All AUROC values:  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "All AUPRC values:  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "All f1-Score values:  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Apple\n",
    "get_cross_validation_seen_food(adata_features_class_doc2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['chemicals'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[122], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## Milk\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m get_cross_validation_seen_food(mdata_features_class_doc2vec)\n",
      "Cell \u001b[1;32mIn[117], line 9\u001b[0m, in \u001b[0;36mget_cross_validation_seen_food\u001b[1;34m(fdata_features_class_normalized)\u001b[0m\n\u001b[0;32m      7\u001b[0m y \u001b[38;5;241m=\u001b[39m fdata_features_class_normalized\u001b[38;5;241m.\u001b[39mcopy()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      8\u001b[0m X \u001b[38;5;241m=\u001b[39m fdata_features_class_normalized\u001b[38;5;241m.\u001b[39mcopy()\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m X \u001b[38;5;241m=\u001b[39m fdata_features_class_normalized\u001b[38;5;241m.\u001b[39mcopy()\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchemicals\u001b[39m\u001b[38;5;124m'\u001b[39m, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     10\u001b[0m X\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m     11\u001b[0m X_smote, y_smote \u001b[38;5;241m=\u001b[39m oversample\u001b[38;5;241m.\u001b[39mfit_resample(X, y)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\foodmine_env\\Lib\\site-packages\\pandas\\core\\frame.py:5258\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5111\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5112\u001b[0m     labels: IndexLabel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5119\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5120\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5121\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5122\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5123\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5256\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5257\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[0;32m   5259\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m   5260\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   5261\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   5262\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   5263\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   5264\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[0;32m   5265\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   5266\u001b[0m     )\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\foodmine_env\\Lib\\site-packages\\pandas\\core\\generic.py:4549\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4547\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4548\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4549\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_drop_axis(labels, axis, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4552\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\foodmine_env\\Lib\\site-packages\\pandas\\core\\generic.py:4591\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4589\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4590\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4591\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4592\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4594\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4595\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\foodmine_env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6699\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6699\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6700\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6701\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['chemicals'] not found in axis\""
     ]
    }
   ],
   "source": [
    "## Milk\n",
    "get_cross_validation_seen_food(mdata_features_class_doc2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance on unseen food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_model_unseen_food(x_other,y_other,x_food,y_food,kfold,n_splits=10,fm1p0_columns=fm1p0_columns):\n",
    "\n",
    "    cross_val_model_fm1 = RandomForestClassifier(max_depth=80,random_state=0)\n",
    "    cross_val_model_fm2 = RandomForestClassifier(max_depth=80,random_state=0)\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits)\n",
    "    \n",
    "    auc_fm1 = []\n",
    "    aup_fm1 = []\n",
    "    f1_score_list_fm1 = []\n",
    "    \n",
    "    auc_fm2 = []\n",
    "    aup_fm2 = []\n",
    "    f1_score_list_fm2 = []\n",
    "    \n",
    "    for i,(test_food,train_food) in enumerate(kfold.split(x_food,y_food)): # test set is kept larger here \n",
    "        \n",
    "        x_other_old = x_other[fm1p0_columns]\n",
    "        x_food_old = x_food[fm1p0_columns]\n",
    "        \n",
    "        cross_val_model_fm2.fit(pd.concat([x_other,x_food.loc[test_food]]),pd.concat([y_other,y_food.loc[test_food]]))\n",
    "        cross_val_model_fm1.fit(pd.concat([x_other_old,x_food_old.loc[test_food]]),pd.concat([y_other,y_food.loc[test_food]]))\n",
    "        \n",
    "        #viz_fm1 = plot_roc_curve(cross_val_model_fm1, x_old.loc[test], y.loc[test],\n",
    "        #                 name='ROC fold {}'.format(i),\n",
    "        #                 alpha=0.3, lw=1)\n",
    "        #viz_fm2 = plot_roc_curve(cross_val_model_fm2, x.loc[test], y.loc[test],\n",
    "        #                 name='ROC fold {}'.format(i),\n",
    "        #                 alpha=0.3, lw=1)\n",
    "        \n",
    "        y_predicted_fm1 = cross_val_model_fm1.predict(x_food_old.loc[train_food])\n",
    "        y_predicted_fm2 = cross_val_model_fm2.predict(x_food.loc[train_food])\n",
    "        \n",
    "        auc_fm1.append(roc_auc_score(np.array(y_food.loc[train_food].tolist()),y_predicted_fm1))\n",
    "        aup_fm1.append(average_precision_score(np.array(y_food.loc[train_food].tolist()),y_predicted_fm1))\n",
    "        f1_score_list_fm1.append(f1_score(np.array(y_food.loc[train_food].tolist()),y_predicted_fm1))\n",
    "        \n",
    "        auc_fm2.append(roc_auc_score(np.array(y_food.loc[train_food].tolist()),y_predicted_fm2))\n",
    "        aup_fm2.append(average_precision_score(np.array(y_food.loc[train_food].tolist()),y_predicted_fm2))\n",
    "        f1_score_list_fm2.append(f1_score(np.array(y_food.loc[train_food].tolist()),y_predicted_fm2))\n",
    "        # plot_confusion_matrix(cross_val_model,x.loc[test],y.loc[test])\n",
    "        \n",
    "    print('------------------------------------------------------------------------------------------------------')\n",
    "    print('FoodMine1.0')\n",
    "    print('Average and SD of AUROC: ', mean(auc_fm1), np.std(auc_fm1))\n",
    "    print('Average and SD of AUPRC:', mean(aup_fm1), np.std(aup_fm1))\n",
    "    print('Average and SD of f1-Score:', mean(f1_score_list_fm1), np.std(f1_score_list_fm1))\n",
    "    print('All AUROC values: ', auc_fm1)\n",
    "    print('All AUPRC values: ', aup_fm1)\n",
    "    print('All f1-Score values: ', f1_score_list_fm1)\n",
    "    print('------------------------------------------------------------------------------------------------------')\n",
    "    print('FoodMine2.0')\n",
    "    print('Average and SD of AUROC: ', mean(auc_fm2), np.std(auc_fm2))\n",
    "    print('Average and SD of AUPRC:', mean(aup_fm2), np.std(aup_fm2))\n",
    "    print('Average and SD of f1-Score:', mean(f1_score_list_fm2), np.std(f1_score_list_fm2))\n",
    "    print('All AUROC values: ', auc_fm2)\n",
    "    print('All AUPRC values: ', aup_fm2)\n",
    "    print('All f1-Score values: ', f1_score_list_fm2)\n",
    "    print('------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "    return mean(auc_fm2), mean(aup_fm2), mean(f1_score_list_fm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chem_ent_ratio_x</th>\n",
       "      <th>chemicals</th>\n",
       "      <th>bigram_score_x</th>\n",
       "      <th>chem_term_count_x</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>class</th>\n",
       "      <th>spectrometry</th>\n",
       "      <th>chromatography</th>\n",
       "      <th>spectrophotometry</th>\n",
       "      <th>chem_ent_ratio_y</th>\n",
       "      <th>chem_term_count_y</th>\n",
       "      <th>bigram_score_y</th>\n",
       "      <th>chem_ent_ratio</th>\n",
       "      <th>chem_term_count</th>\n",
       "      <th>bigram_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.829169</td>\n",
       "      <td>0.982137</td>\n",
       "      <td>-0.094145</td>\n",
       "      <td>-2.726737</td>\n",
       "      <td>1.988802</td>\n",
       "      <td>-3.287893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.398161</td>\n",
       "      <td>-0.680581</td>\n",
       "      <td>-0.014942</td>\n",
       "      <td>-0.365835</td>\n",
       "      <td>-0.685722</td>\n",
       "      <td>-1.055222</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.304260</td>\n",
       "      <td>-1.165422</td>\n",
       "      <td>-0.358080</td>\n",
       "      <td>-2.827604</td>\n",
       "      <td>1.150531</td>\n",
       "      <td>-0.974158</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.008594</td>\n",
       "      <td>-0.866767</td>\n",
       "      <td>-0.076545</td>\n",
       "      <td>-1.335826</td>\n",
       "      <td>0.230017</td>\n",
       "      <td>-1.727068</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.908859</td>\n",
       "      <td>-1.621425</td>\n",
       "      <td>-3.386691</td>\n",
       "      <td>0.013008</td>\n",
       "      <td>0.014096</td>\n",
       "      <td>0.085421</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.930623</td>\n",
       "      <td>0.606643</td>\n",
       "      <td>-1.623046</td>\n",
       "      <td>-2.966842</td>\n",
       "      <td>0.356345</td>\n",
       "      <td>-2.050584</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.175221</td>\n",
       "      <td>-0.166890</td>\n",
       "      <td>-0.695077</td>\n",
       "      <td>-1.659369</td>\n",
       "      <td>1.041467</td>\n",
       "      <td>-0.973924</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.999931</td>\n",
       "      <td>-0.205728</td>\n",
       "      <td>-2.001056</td>\n",
       "      <td>-0.408468</td>\n",
       "      <td>1.569245</td>\n",
       "      <td>-1.439709</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.860390</td>\n",
       "      <td>2.208683</td>\n",
       "      <td>-2.119556</td>\n",
       "      <td>1.693405</td>\n",
       "      <td>-0.015089</td>\n",
       "      <td>-3.426805</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.160362</td>\n",
       "      <td>0.474620</td>\n",
       "      <td>-0.448323</td>\n",
       "      <td>-1.730325</td>\n",
       "      <td>-0.301157</td>\n",
       "      <td>-1.429893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2305 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     chem_ent_ratio_x chemicals  bigram_score_x  chem_term_count_x         0  \\\n",
       "0                 0.0        []             0.0                0.0  0.829169   \n",
       "1                 0.0        []             0.0                0.0  1.398161   \n",
       "2                 0.0        []             0.0                0.0 -0.304260   \n",
       "3                 0.0        []             0.0                0.0 -1.008594   \n",
       "4                 0.0        []             0.0                0.0 -2.908859   \n",
       "..                ...       ...             ...                ...       ...   \n",
       "230               NaN       NaN             NaN                NaN  1.930623   \n",
       "231               NaN       NaN             NaN                NaN -0.175221   \n",
       "232               NaN       NaN             NaN                NaN -0.999931   \n",
       "233               NaN       NaN             NaN                NaN  3.860390   \n",
       "234               NaN       NaN             NaN                NaN  0.160362   \n",
       "\n",
       "            1         2         3         4         5  ...  class  \\\n",
       "0    0.982137 -0.094145 -2.726737  1.988802 -3.287893  ...    0.0   \n",
       "1   -0.680581 -0.014942 -0.365835 -0.685722 -1.055222  ...    1.0   \n",
       "2   -1.165422 -0.358080 -2.827604  1.150531 -0.974158  ...    1.0   \n",
       "3   -0.866767 -0.076545 -1.335826  0.230017 -1.727068  ...    1.0   \n",
       "4   -1.621425 -3.386691  0.013008  0.014096  0.085421  ...    1.0   \n",
       "..        ...       ...       ...       ...       ...  ...    ...   \n",
       "230  0.606643 -1.623046 -2.966842  0.356345 -2.050584  ...    1.0   \n",
       "231 -0.166890 -0.695077 -1.659369  1.041467 -0.973924  ...    1.0   \n",
       "232 -0.205728 -2.001056 -0.408468  1.569245 -1.439709  ...    1.0   \n",
       "233  2.208683 -2.119556  1.693405 -0.015089 -3.426805  ...    0.0   \n",
       "234  0.474620 -0.448323 -1.730325 -0.301157 -1.429893  ...    0.0   \n",
       "\n",
       "     spectrometry  chromatography  spectrophotometry  chem_ent_ratio_y  \\\n",
       "0             0.0             0.0                0.0               0.0   \n",
       "1             1.0             0.0                0.0               0.0   \n",
       "2             0.0             0.0                0.0               0.0   \n",
       "3             0.0             1.0                0.0               0.0   \n",
       "4             0.0             1.0                0.0               0.0   \n",
       "..            ...             ...                ...               ...   \n",
       "230           0.0             0.0                0.0               NaN   \n",
       "231           0.0             0.0                0.0               NaN   \n",
       "232           0.0             0.0                0.0               NaN   \n",
       "233           0.0             0.0                0.0               NaN   \n",
       "234           0.0             0.0                0.0               NaN   \n",
       "\n",
       "     chem_term_count_y  bigram_score_y  chem_ent_ratio  chem_term_count  \\\n",
       "0                  0.0             0.0             NaN              NaN   \n",
       "1                  0.0             0.0             NaN              NaN   \n",
       "2                  0.0             0.0             NaN              NaN   \n",
       "3                  0.0             0.0             NaN              NaN   \n",
       "4                  0.0             0.0             NaN              NaN   \n",
       "..                 ...             ...             ...              ...   \n",
       "230                NaN             NaN             0.0              0.0   \n",
       "231                NaN             NaN             0.0              0.0   \n",
       "232                NaN             NaN             0.0              0.0   \n",
       "233                NaN             NaN             0.0              0.0   \n",
       "234                NaN             NaN             0.0              0.0   \n",
       "\n",
       "     bigram_score  \n",
       "0             NaN  \n",
       "1             NaN  \n",
       "2             NaN  \n",
       "3             NaN  \n",
       "4             NaN  \n",
       "..            ...  \n",
       "230           0.6  \n",
       "231           0.5  \n",
       "232           0.0  \n",
       "233           0.0  \n",
       "234           1.0  \n",
       "\n",
       "[2305 rows x 81 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_foods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cross_validation_unseen_food(other_data_features_class,fdata_features_class):\n",
    "\n",
    "    repeat = 1\n",
    "\n",
    "    for _ in tqdm(range(repeat)):\n",
    "        oversample = SMOTE()\n",
    "        y_other = other_data_features_class.copy()['class']\n",
    "        X_other = other_data_features_class.copy().drop('class', axis = 1)\n",
    "        X_other = other_data_features_class.copy().drop('chemicals', axis = 1)\n",
    "        X_other.columns = X_other.columns.astype(str)\n",
    "        X_other_smote, y_other_smote = oversample.fit_resample(X_other, y_other)\n",
    "        y_food = fdata_features_class.copy()['class']\n",
    "        X_food = fdata_features_class.copy().drop('class', axis = 1)\n",
    "        X_food = fdata_features_class.copy().drop('chemicals', axis = 1)\n",
    "        X_food.columns = X_food.columns.astype(str)\n",
    "        X_food_smote, y_food_smote = oversample.fit_resample(X_food, y_food)\n",
    "        kfold = StratifiedKFold(n_splits=10)\n",
    "        auc_fm2, aup_fm2, f1_fm2 = xgboost_model_unseen_food(X_other_smote, y_other_smote,X_food_smote, y_food_smote,kfold,n_splits=10)\n",
    "        \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nSMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[132], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## Garlic\u001b[39;00m\n\u001b[0;32m      2\u001b[0m other_foods \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([cdata_features_class_doc2vec,bdata_features_class_doc2vec,adata_features_class_doc2vec,mdata_features_class_doc2vec])\n\u001b[1;32m----> 3\u001b[0m get_cross_validation_unseen_food(other_foods,gdata_features_class_doc2vec)\n",
      "Cell \u001b[1;32mIn[131], line 11\u001b[0m, in \u001b[0;36mget_cross_validation_unseen_food\u001b[1;34m(other_data_features_class, fdata_features_class)\u001b[0m\n\u001b[0;32m      9\u001b[0m X_other \u001b[38;5;241m=\u001b[39m other_data_features_class\u001b[38;5;241m.\u001b[39mcopy()\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchemicals\u001b[39m\u001b[38;5;124m'\u001b[39m, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     10\u001b[0m X_other\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m X_other\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m X_other_smote, y_other_smote \u001b[38;5;241m=\u001b[39m oversample\u001b[38;5;241m.\u001b[39mfit_resample(X_other, y_other)\n\u001b[0;32m     12\u001b[0m y_food \u001b[38;5;241m=\u001b[39m fdata_features_class\u001b[38;5;241m.\u001b[39mcopy()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     13\u001b[0m X_food \u001b[38;5;241m=\u001b[39m fdata_features_class\u001b[38;5;241m.\u001b[39mcopy()\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\foodmine_env\\Lib\\site-packages\\imblearn\\base.py:77\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     75\u001b[0m check_classification_targets(y)\n\u001b[0;32m     76\u001b[0m arrays_transformer \u001b[38;5;241m=\u001b[39m ArraysTransformer(X, y)\n\u001b[1;32m---> 77\u001b[0m X, y, binarize_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X_y(X, y)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy_ \u001b[38;5;241m=\u001b[39m check_sampling_strategy(\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampling_type\n\u001b[0;32m     81\u001b[0m )\n\u001b[0;32m     83\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_resample(X, y)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\foodmine_env\\Lib\\site-packages\\imblearn\\base.py:132\u001b[0m, in \u001b[0;36mBaseSampler._check_X_y\u001b[1;34m(self, X, y, accept_sparse)\u001b[0m\n\u001b[0;32m    130\u001b[0m     accept_sparse \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    131\u001b[0m y, binarize_y \u001b[38;5;241m=\u001b[39m check_target_type(y, indicate_one_vs_all\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 132\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, y, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse)\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y, binarize_y\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\foodmine_env\\Lib\\site-packages\\sklearn\\base.py:584\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    582\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 584\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    585\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\foodmine_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1101\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1103\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[1;32m-> 1106\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1107\u001b[0m     X,\n\u001b[0;32m   1108\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   1109\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[0;32m   1110\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1111\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[0;32m   1112\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   1113\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m   1114\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m   1115\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[0;32m   1116\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[0;32m   1117\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[0;32m   1118\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1119\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1120\u001b[0m )\n\u001b[0;32m   1122\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1124\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\foodmine_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    915\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    916\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    917\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    918\u001b[0m         )\n\u001b[0;32m    920\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 921\u001b[0m         _assert_all_finite(\n\u001b[0;32m    922\u001b[0m             array,\n\u001b[0;32m    923\u001b[0m             input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    924\u001b[0m             estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    925\u001b[0m             allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    926\u001b[0m         )\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    929\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\foodmine_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m     )\n\u001b[1;32m--> 161\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nSMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "## Garlic\n",
    "other_foods = pd.concat([cdata_features_class_doc2vec,bdata_features_class_doc2vec,adata_features_class_doc2vec,mdata_features_class_doc2vec])\n",
    "get_cross_validation_unseen_food(other_foods,gdata_features_class_doc2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:18<00:00, 18.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------\n",
      "FoodMine1.0\n",
      "Average and SD of AUROC:  0.7455615942028986 0.21070890790249047\n",
      "Average and SD of AUPRC: 0.7195966006789318 0.18265392834404642\n",
      "Average and SD of f1-Score: 0.6150366104522164 0.3776704566202394\n",
      "All AUROC values:  [0.5226449275362319, 0.4547101449275362, 0.4782608695652174, 0.49999999999999994, 0.891304347826087, 0.9347826086956521, 0.9347826086956522, 0.9130434782608696, 0.891304347826087, 0.9347826086956522]\n",
      "All AUPRC values:  [0.5047795251310515, 0.49586288416075647, 0.4927536231884058, 0.5, 0.8311036789297659, 0.8846153846153846, 0.8985507246376812, 0.8518518518518519, 0.8214285714285714, 0.9150197628458498]\n",
      "All f1-Score values:  [0.15384615384615383, 0.13333333333333333, 0.07692307692307691, 0.25806451612903225, 0.8979591836734695, 0.9387755102040816, 0.9361702127659574, 0.92, 0.9019607843137255, 0.9333333333333332]\n",
      "------------------------------------------------------------------------------------------------------\n",
      "FoodMine2.0\n",
      "Average and SD of AUROC:  0.8314311594202899 0.08713791655335948\n",
      "Average and SD of AUPRC: 0.7762953426313749 0.09205440568353584\n",
      "Average and SD of f1-Score: 0.8274897794803182 0.10224962346564136\n",
      "All AUROC values:  [0.7445652173913043, 0.7871376811594203, 0.7173913043478262, 0.7173913043478262, 0.8043478260869564, 0.9130434782608696, 0.9565217391304348, 0.826086956521739, 0.9130434782608696, 0.9347826086956521]\n",
      "All AUPRC values:  [0.6739733740900131, 0.7331190898345153, 0.686335403726708, 0.6630434782608696, 0.734113712374582, 0.8518518518518519, 0.9366729678638942, 0.7473763118440779, 0.8518518518518519, 0.8846153846153846]\n",
      "All f1-Score values:  [0.7391304347826085, 0.7916666666666666, 0.6486486486486486, 0.6976744186046512, 0.8163265306122449, 0.92, 0.9565217391304348, 0.8461538461538461, 0.92, 0.9387755102040816]\n",
      "------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Cocoa\n",
    "other_foods = pd.concat([gdata_features_class_doc2vec,bdata_features_class_doc2vec,adata_features_class_doc2vec,mdata_features_class_doc2vec])\n",
    "get_cross_validation_unseen_food(other_foods,cdata_features_class_doc2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:21<00:00, 21.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------\n",
      "FoodMine1.0\n",
      "Average and SD of AUROC:  0.3816666666666667 0.2068883219946882\n",
      "Average and SD of AUPRC: 0.5056998556998556 0.06694085093847828\n",
      "Average and SD of f1-Score: 0.21746031746031746 0.16361337770663945\n",
      "All AUROC values:  [0.5833333333333334, 0.5833333333333334, 0.5, 0.5833333333333334, 0.4833333333333334, 0.5, 0.2, 0.2833333333333333, 0.1, 0.0]\n",
      "All AUPRC values:  [0.5833333333333334, 0.5555555555555556, 0.5, 0.5555555555555556, 0.5378787878787878, 0.5454545454545454, 0.5454545454545454, 0.387012987012987, 0.3922077922077922, 0.45454545454545453]\n",
      "All f1-Score values:  [0.2857142857142857, 0.4444444444444444, 0.25, 0.4444444444444444, 0.25, 0.0, 0.0, 0.3333333333333333, 0.16666666666666666, 0.0]\n",
      "------------------------------------------------------------------------------------------------------\n",
      "FoodMine2.0\n",
      "Average and SD of AUROC:  0.515 0.11016401913107159\n",
      "Average and SD of AUPRC: 0.5458080808080809 0.06105392181709572\n",
      "Average and SD of f1-Score: 0.2943001443001443 0.17476892184256201\n",
      "All AUROC values:  [0.5833333333333334, 0.33333333333333337, 0.5833333333333334, 0.5, 0.4833333333333334, 0.5833333333333334, 0.36666666666666664, 0.7, 0.6, 0.4166666666666667]\n",
      "All AUPRC values:  [0.5555555555555556, 0.5, 0.5555555555555556, 0.5, 0.5378787878787878, 0.6212121212121212, 0.49696969696969695, 0.6727272727272727, 0.5636363636363637, 0.45454545454545453]\n",
      "All f1-Score values:  [0.4444444444444444, 0.0, 0.4444444444444444, 0.25, 0.25, 0.2857142857142857, 0.3636363636363636, 0.5714285714285715, 0.33333333333333337, 0.0]\n",
      "------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Basil\n",
    "other_foods = pd.concat([gdata_features_class_doc2vec,cdata_features_class_doc2vec,adata_features_class_doc2vec,mdata_features_class_doc2vec])\n",
    "get_cross_validation_unseen_food(other_foods,bdata_features_class_doc2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:19<00:00, 19.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------\n",
      "FoodMine1.0\n",
      "Average and SD of AUROC:  0.7541981792717086 0.20173174640334612\n",
      "Average and SD of AUPRC: 0.7331111183790664 0.18376070506257436\n",
      "Average and SD of f1-Score: 0.6179401408230707 0.3692218482255413\n",
      "All AUROC values:  [0.5045168067226891, 0.49964985994397754, 0.47478991596638653, 0.5546218487394958, 0.9201680672268907, 0.9159663865546218, 0.9411764705882353, 0.9117647058823529, 0.903361344537815, 0.9159663865546218]\n",
      "All AUPRC values:  [0.5002951632095252, 0.5019177126917712, 0.4903038138332256, 0.54421768707483, 0.8881213502350092, 0.8839689722042663, 0.9152249134948097, 0.8685958254269449, 0.8657598632673409, 0.8727058823529412]\n",
      "All f1-Score values:  [0.14492753623188406, 0.14285714285714285, 0.13793103448275865, 0.24285714285714285, 0.9198312236286919, 0.9152542372881355, 0.9411764705882353, 0.9135802469135801, 0.9029535864978903, 0.9180327868852459]\n",
      "------------------------------------------------------------------------------------------------------\n",
      "FoodMine2.0\n",
      "Average and SD of AUROC:  0.8791841736694679 0.08385864904410231\n",
      "Average and SD of AUPRC: 0.8411297409707479 0.08958206130935878\n",
      "Average and SD of f1-Score: 0.8711170784082676 0.09565609133961259\n",
      "All AUROC values:  [0.7653711484593838, 0.7701680672268908, 0.8067226890756303, 0.76890756302521, 0.9411764705882353, 0.9663865546218489, 0.9369747899159664, 0.9369747899159664, 0.9453781512605044, 0.9537815126050421]\n",
      "All AUPRC values:  [0.7142592568739663, 0.7215014014705285, 0.7712074303405572, 0.7300653594771243, 0.9001367989056086, 0.94711438294326, 0.890628978864273, 0.8988261971455249, 0.9130523177012739, 0.9245052859853617]\n",
      "All f1-Score values:  [0.7454545454545454, 0.7533632286995516, 0.7850467289719626, 0.736842105263158, 0.9435483870967741, 0.9666666666666667, 0.9402390438247011, 0.9387755102040817, 0.9465020576131686, 0.9547325102880658]\n",
      "------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Apple\n",
    "other_foods = pd.concat([gdata_features_class_doc2vec,cdata_features_class_doc2vec,bdata_features_class_doc2vec,mdata_features_class_doc2vec])\n",
    "get_cross_validation_unseen_food(other_foods,adata_features_class_doc2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:20<00:00, 20.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------\n",
      "FoodMine1.0\n",
      "Average and SD of AUROC:  0.4926282051282051 0.06966344494876907\n",
      "Average and SD of AUPRC: 0.5162673992673993 0.031023000480114728\n",
      "Average and SD of f1-Score: 0.09528822055137846 0.0633249372331306\n",
      "All AUROC values:  [0.5384615384615384, 0.5384615384615384, 0.5384615384615384, 0.5384615384615384, 0.5, 0.5, 0.5, 0.5384615384615384, 0.4230769230769231, 0.31089743589743585]\n",
      "All AUPRC values:  [0.5384615384615385, 0.5384615384615385, 0.5384615384615385, 0.5384615384615385, 0.5, 0.5, 0.52, 0.556923076923077, 0.48, 0.45190476190476186]\n",
      "All f1-Score values:  [0.14285714285714288, 0.14285714285714288, 0.14285714285714288, 0.14285714285714288, 0.0, 0.13333333333333336, 0.0, 0.14285714285714288, 0.0, 0.10526315789473685]\n",
      "------------------------------------------------------------------------------------------------------\n",
      "FoodMine2.0\n",
      "Average and SD of AUROC:  0.6820512820512821 0.08892483658389656\n",
      "Average and SD of AUPRC: 0.6589397824397825 0.09262581159270378\n",
      "Average and SD of f1-Score: 0.584401818698494 0.14832375464401895\n",
      "All AUROC values:  [0.8076923076923077, 0.6923076923076923, 0.8076923076923076, 0.7307692307692307, 0.6538461538461539, 0.5384615384615385, 0.7243589743589745, 0.6923076923076923, 0.6282051282051282, 0.5448717948717949]\n",
      "All AUPRC values:  [0.8076923076923077, 0.6923076923076923, 0.7564102564102564, 0.7019230769230769, 0.6153846153846154, 0.5209790209790209, 0.6923076923076923, 0.7046153846153846, 0.5866666666666667, 0.5111111111111111]\n",
      "All f1-Score values:  [0.761904761904762, 0.5555555555555556, 0.8, 0.6666666666666667, 0.5714285714285714, 0.4999999999999999, 0.6956521739130435, 0.5555555555555556, 0.47058823529411764, 0.26666666666666666]\n",
      "------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Milk\n",
    "other_foods = pd.concat([gdata_features_class_doc2vec,cdata_features_class_doc2vec,bdata_features_class_doc2vec,adata_features_class_doc2vec])\n",
    "get_cross_validation_unseen_food(other_foods,mdata_features_class_doc2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foodmine_env",
   "language": "python",
   "name": "foodmine_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
